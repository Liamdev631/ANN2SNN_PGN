{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 08:33:41.792423: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-12 08:33:41.811640: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import inspect\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tensorflow.python.keras import backend\n",
    "#from tensorflow.python.data.benchmarks import mnist\n",
    "#from tensorflow.python.keras.utils import to_categorical\n",
    "\n",
    "from snntoolbox.bin.run import main\n",
    "from snntoolbox.utils.utils import import_configparser\n",
    "from tests.parsing.models.pytorch import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeWarning",
     "evalue": "Data set file 'x_test.npz' or 'y_test.npz' was not found in specified data set path /home/liamb/temp/1731371623.0417182.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeWarning\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 60\u001b[0m\n\u001b[1;32m     55\u001b[0m shutil\u001b[38;5;241m.\u001b[39mcopyfile(source_path, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path_wd, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodules.py\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# RUN SNN TOOLBOX #\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m###################\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_filepath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torchenv/lib/python3.12/site-packages/snntoolbox/bin/run.py:30\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msnntoolbox\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbin\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m update_setup, run_pipeline\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filepath \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_setup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     run_pipeline(config)\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torchenv/lib/python3.12/site-packages/snntoolbox/bin/utils.py:431\u001b[0m, in \u001b[0;36mupdate_setup\u001b[0;34m(config_filepath)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m(\n\u001b[1;32m    426\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo data set file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_norm.npz\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m found in specified data set path \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    427\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. Add it, or disable normalization.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(dataset_path))\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dataset_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnpz\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    429\u001b[0m         dataset_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_test.npz\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    430\u001b[0m         dataset_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_test.npz\u001b[39m\u001b[38;5;124m'\u001b[39m))):\n\u001b[0;32m--> 431\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m(\n\u001b[1;32m    432\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData set file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_test.npz\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_test.npz\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m was not found in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    433\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecified data set path \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(dataset_path))\n\u001b[1;32m    435\u001b[0m sample_idxs_to_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimulation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_idxs_to_test\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m    436\u001b[0m num_to_test \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mgetint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimulation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_to_test\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeWarning\u001b[0m: Data set file 'x_test.npz' or 'y_test.npz' was not found in specified data set path /home/liamb/temp/1731371623.0417182."
     ]
    }
   ],
   "source": [
    "# Pytorch to Keras parser needs image_data_format == channel_first.\n",
    "backend.set_image_data_format('channels_first')\n",
    "\n",
    "# Define path where model and output files will be stored.\n",
    "# The user is responsible for cleaning up this temporary directory.\n",
    "path_wd = os.path.abspath(os.path.join(os.path.dirname(os.path.realpath(\n",
    "    os.path.abspath(''))), '..', 'temp', str(time.time())))\n",
    "os.makedirs(path_wd)\n",
    "\n",
    "# Create a config file with experimental setup for SNN Toolbox.\n",
    "configparser = import_configparser()\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "config['paths'] = {\n",
    "    'path_wd': path_wd,             # Path to model.\n",
    "    'dataset_path': path_wd,        # Path to dataset.\n",
    "\t'filename_ann': './saved_models/resnet20_cifar10.pth' # Name of input model.\n",
    "}\n",
    "\n",
    "config['tools'] = {\n",
    "    'evaluate_ann': True, # Test ANN on dataset before conversion.\n",
    "    'normalize': False # Normalize weights for full dynamic range.\n",
    "}\n",
    "\n",
    "config['simulation'] = {\n",
    "    'simulator': 'INI',             # Chooses execution backend of SNN toolbox.\n",
    "    'duration': 50,                 # Number of time steps to run each sample.\n",
    "    'num_to_test': 100,             # How many test samples to run.\n",
    "    'batch_size': 128,               # Batch size for simulation.\n",
    "    'keras_backend': 'tensorflow'   # Which keras backend to use.\n",
    "}\n",
    "\n",
    "config['input'] = {\n",
    "    'model_lib': 'pytorch'          # Input model is defined in pytorch.\n",
    "}\n",
    "\n",
    "config['output'] = {\n",
    "    'plot_vars': {                  # Various plots (slows down simulation).\n",
    "        'spiketrains',              # Leave section empty to turn off plots.\n",
    "        'spikerates',\n",
    "        'activations',\n",
    "        'correlation',\n",
    "        'v_mem',\n",
    "        'error_t'}\n",
    "}\n",
    "\n",
    "# Store config file.\n",
    "config_filepath = os.path.join(path_wd, 'config')\n",
    "with open(config_filepath, 'w') as configfile:\n",
    "    config.write(configfile)\n",
    "\n",
    "# Need to copy model definition over to ``path_wd`` (needs to be in same dir as\n",
    "# the weights saved above).\n",
    "source_path = inspect.getfile(Model)\n",
    "shutil.copyfile(source_path, os.path.join(path_wd, 'modules.py'))\n",
    "\n",
    "# RUN SNN TOOLBOX #\n",
    "###################\n",
    "\n",
    "main(config_filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
